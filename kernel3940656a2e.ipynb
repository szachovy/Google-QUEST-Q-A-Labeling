{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Google Quest QA Labeling"},{"metadata":{},"cell_type":"markdown","source":"## 1. Data retrieval"},{"metadata":{},"cell_type":"markdown","source":"### 1.1. Import modules"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\nimport plotly.graph_objs as go\nfrom matplotlib_venn import venn2\n\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.decomposition import TruncatedSVD\nfrom sklearn.preprocessing import LabelBinarizer\n\n# TODO in the future\n# from sklearn.linear_model import MultiTaskElasticNet\n\nimport json\nimport requests\nimport sys\n\n# import tensorflow_hub as hub\n# from transformers import DistilBertTokenizer, DistilBertModel\nfrom transformers import BertTokenizer, BertModel\nfrom tqdm import tqdm\n\nfrom sklearn.model_selection import KFold\nfrom scipy.stats import spearmanr\nfrom sklearn.linear_model import MultiTaskElasticNet\nimport tensorflow as tf\nimport torch\nfrom keras.callbacks import Callback\nfrom keras.optimizers import Adam\nfrom keras.models import Model, Sequential\nfrom keras.layers import LSTM, Input, Dense, Dropout\n\n\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Offline models download"},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install ../input/sacremoses/sacremoses-master/\n!pip install ../input/transformers/transformers-master/\n!ls ../input\n\n# add also bert-base-uncased (pytorch_model.bin, vocab.txt, config.json)to input dir (Add data)\nsys.path.insert(0, \"../input/transformers/transformers-master/\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 1.2. Reading Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_set = pd.read_csv('../input/google-quest-challenge/train.csv')\nX_test = pd.read_csv('../input/google-quest-challenge/test.csv')\nsample_submission = pd.read_csv('../input/google-quest-challenge/sample_submission.csv')\nX_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_set = np.split(train_set, [train_set.columns.get_loc('question_asker_intent_understanding')], axis=1)\nX_train = train_set[0]\nX_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y_train = pd.concat([X_train['qa_id'], train_set[1]], axis=1)\nY_train","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2. Exploratory Data analysis"},{"metadata":{},"cell_type":"markdown","source":"### 2.1. Data Description"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Size of X_train', X_train.shape)\nprint('Size of Y_train', Y_train.shape)\nprint('Size of X_test', X_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2.2. Host distribution visualization"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_host_dist = X_train[\"host\"].value_counts()\nX_test_host_dist = X_test[\"host\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def host_distribution(distribution, title):\n    fig = px.pie(names=distribution.index, \n         values=distribution.values, \n         title=title,\n         width=800, \n         height=800)\n\n    fig.update_traces(textposition='inside', textinfo='percent+label')\n    fig.update_layout(showlegend=True)\n    fig.show()\n    \nhost_distribution(X_train_host_dist, 'Host data distribution on train data')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"host_distribution(X_test_host_dist, 'Host data distribution on test data')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2.3. Categories distribution"},{"metadata":{"trusted":true},"cell_type":"code","source":"def categories_distribution(categories, title):\n    category_share = pd.DataFrame({'share': categories.value_counts() / categories.count()})\n    category_share['category'] = category_share.index   \n        \n    fig = px.bar(category_share, x='category', y='share',\n            labels={'share':'share in %'},\n            title=title)\n        \n    fig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"categories_distribution(X_train['category'], 'X_train categories distribution barplot')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"categories_distribution(X_test['category'], 'X_test categories distribution barplot')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2.4. Common features in training and testing set (Venn diagrams)"},{"metadata":{"trusted":true},"cell_type":"code","source":"def venn_diagrams(columns, plot_num, title):\n    plt.subplot(plot_num)\n    venn2([set(columns[0].unique()), set(columns[1].unique())], set_labels = ('Train set', 'Test set'))\n    plt.title(title)\n    plt.show()\n    \nvenn_diagrams([X_train['question_user_name'], X_test['question_user_name']], 111, 'Common question_user_name in training and test data')\nvenn_diagrams([X_train['answer_user_name'], X_test['answer_user_name']], 121, 'Common answer_user_name in training and test data')\nvenn_diagrams([X_train['question_title'], X_test['question_title']], 131, 'Common question_title in training and test data')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2.5. Length of contents"},{"metadata":{"trusted":true},"cell_type":"code","source":"def distribution_imposition(first_col, second_col, title):\n    plt.figure(figsize=(20, 6))\n    sns.distplot(first_col.str.len())\n    sns.distplot(second_col.str.len())\n    plt.title(title)\n    plt.show()\n        \ndistribution_imposition(X_train['question_title'], X_test['question_title'], 'Length of Question Title represented as cumulative distribution plots')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"distribution_imposition(X_train['question_body'], X_test['question_body'], 'Length of Question Body represented as cumulative distribution plots')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"distribution_imposition(X_train['answer'], X_test['answer'], 'Length of Question Body represented as cumulative distribution plots')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2.6. Most popular questions"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.groupby('question_title').count()['qa_id'].sort_values(ascending=False).head(25)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train[X_train['question_title'] == 'What is the best introductory Bayesian statistics textbook?']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3. Feature Engineering"},{"metadata":{"trusted":true},"cell_type":"code","source":"class Feature_Engineering(object):\n    '''\n    Helper class used for Feature engineering purposes.\n    \n    '''\n    def __init__(self, dataframe):\n        self.dataframe = dataframe\n        with open(\"../input/charset/charset.json\", encoding=\"utf8\") as json_file:\n            self.charset  = json.load(json_file)\n        \n        self.vectorizer = TfidfVectorizer(ngram_range=(1, 3))\n        self.tsvd = TruncatedSVD(n_components = 128, n_iter=5)\n        \n#         self.tokenizer = DistilBertTokenizer.from_pretrained('../input/distilbertbaseuncased/') \n#         self.model = DistilBertModel.from_pretrained('../input/distilbertbaseuncased/')\n        \n        self.tokenizer = BertTokenizer.from_pretrained('../input/bertlargeuncased/bert-large-uncased/')  \n        self.model = BertModel.from_pretrained('../input/bertlargeuncased/bert-large-uncased/')\n        \n        self.binarizer = LabelBinarizer()\n\n\n    def unconstrained_chars(self, column, index):\n        df = self.dataframe[column][index]\n        for char in self.charset['CHARS']:\n            df = df.replace(char, '')\n        return df\n\n    def shortcuts_removal(self, column, index):\n        return ' '.join(list(map(lambda word: self.find_and_replace(word), self.dataframe[column][index].split())))\n        \n    def lower_case(self, column):\n        return self.dataframe[column].str.lower()\n        \n    \n    def find_and_replace(self, word):\n        for key, value in self.charset['SHORTCUTS'].items():\n            if key == word:\n                return value\n        return word\n\n    def flow(self, column):\n        self.dataframe[column] = self.lower_case(column)\n        for index in range(self.dataframe[column].shape[0]):\n            self.dataframe[column][index] = self.unconstrained_chars(column, index)\n            self.dataframe[column][index] = self.shortcuts_removal(column, index)\n\n        return self.dataframe[column]\n    \n    def tfidf_vec(self, column):\n        return list(self.tsvd.fit_transform(self.vectorizer.fit_transform(self.dataframe[column].values)))\n    \n    def binarize(self, column, other_df):\n        if len(self.dataframe[column].value_counts()) < len(other_df[column].value_counts()):\n            diff = abs(len(self.dataframe[column].value_counts()) - len(other_df[column].value_counts()))\n            return list(np.concatenate([list(self.binarizer.fit_transform(self.dataframe[column].values)), np.zeros((self.dataframe.shape[0], diff))], axis=1))\n        return list(self.binarizer.fit_transform(self.dataframe[column].values))\n    \n    def bert_separators(self, column):\n        for index in range(self.dataframe[column].shape[0]):\n            self.dataframe[column][index] = self.dataframe[column][index].split('.')\n            \n        return self.dataframe[column]\n    \n    def model_conf(self):\n        self.model.cpu()\n#         self.model.cuda()\n        \n    def make_vectors(self, column):\n        ids = self.dataframe[column].str.slice(0, 500).apply(self.tokenizer.encode)\n        vectors = []\n\n        for column in tqdm(ids):\n            input_ids = torch.Tensor(column).to(torch.int64).unsqueeze(0)\n            try:\n                outputs = self.model(input_ids.cpu())\n#                 outputs = self.model(input_ids.cuda())\n                vectors.append(outputs[0].detach().cpu().numpy().max(axis = 1))\n\n            except:\n                vectors.append(np.zeros(outputs[0].detach().cpu().numpy().max(axis = 1)).shape)\n        \n        return vectors","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3.1. Data Cleaning"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_features = Feature_Engineering(X_train)\ntest_features = Feature_Engineering(X_test)\n\nX_train['question_title'] = train_features.flow('question_title')\nX_train['question_body'] = train_features.flow('question_body')\nX_train['answer'] = train_features.flow('answer')\nX_test['question_title'] = test_features.flow('question_title')\nX_test['question_body'] = test_features.flow('question_body')\nX_test['answer'] = test_features.flow('answer')\n\nX_train.drop(columns=['question_user_page', 'answer_user_page', 'url'], inplace=True)\nX_test.drop(columns=['question_user_page', 'answer_user_page', 'url'], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3.2. Transform frequent operations on documents"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train['question_title_tfidf_vec'] = train_features.tfidf_vec('question_title')\nX_train['question_body_tfidf_vec'] = train_features.tfidf_vec('question_body')\nX_train['answer_tfidf_vec'] = train_features.tfidf_vec('answer')\n\nX_test['question_title_tfidf_vec'] = test_features.tfidf_vec('question_title')\nX_test['question_body_tfidf_vec'] = test_features.tfidf_vec('question_body')\nX_test['answer_tfidf_vec'] = test_features.tfidf_vec('answer')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3.3. Encoding categorical features"},{"metadata":{"trusted":true},"cell_type":"code","source":"# X_train['category_vec'] = list(LabelBinarizer().fit_transform(X_train['category'].values))\n# X_train['question_user_name_vec'] = list(LabelBinarizer().fit_transform(X_train['question_user_name'].values))\n# X_train['answer_user_name_vec'] = list(LabelBinarizer().fit_transform(X_train['answer_user_name'].values))\n# X_train['host_vec'] = list(LabelBinarizer().fit_transform(X_train['host'].values))\n\n# diff = abs(len(X_test['question_user_name'].value_counts()) - len(X_train['question_user_name'].value_counts()))\n# d = np.zeros((X_test.shape[0], diff))\n# a = list(LabelBinarizer().fit_transform(X_train['question_user_name'].values))\n# b = list(LabelBinarizer().fit_transform(X_test['question_user_name'].values))\n# a = np.array(a)\n# c = np.concatenate([b, d], axis=1)\n# print(np.array(a).shape)\n# print(np.array(b).shape)\n# print(np.array(c).shape)\n\nX_train['category_vec'] = train_features.binarize('category', X_test)\nX_train['question_user_name_vec'] = train_features.binarize('question_user_name', X_test)\nX_train['answer_user_name_vec'] = train_features.binarize('answer_user_name', X_test)\nX_train['host_vec'] = train_features.binarize('host', X_test)\n\nX_test['category_vec'] = test_features.binarize('category', X_train)\nX_test['question_user_name_vec'] = test_features.binarize('question_user_name', X_train)\nX_test['answer_user_name_vec'] = test_features.binarize('answer_user_name', X_train)\nX_test['host_vec'] = test_features.binarize('host', X_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3.4. Bidirectional Encoder Representations from Transformers (BERT)"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_features.model_conf()\ntest_features.model_conf()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train['question_title'] = train_features.bert_separators('question_title')\nX_train['question_body'] = train_features.bert_separators('question_body')\nX_train['answer'] = train_features.bert_separators('answer')\n\nX_test['question_title'] = test_features.bert_separators('question_title')\nX_test['question_body'] = test_features.bert_separators('question_body')\nX_test['answer'] = test_features.bert_separators('answer')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"question_title_vectors_train = train_features.make_vectors(\"question_title\")\nquestion_body_vectors_train = train_features.make_vectors(\"question_body\")\nanswer_vectors_train = train_features.make_vectors(\"answer\")\n\nquestion_title_vectors_test = test_features.make_vectors(\"question_title\")\nquestion_body_vectors_test = test_features.make_vectors(\"question_body\")\nanswer_vectors_test = test_features.make_vectors(\"answer\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nX_train = np.concatenate([\n                     np.vstack(X_train['category_vec']),\n                     np.vstack(X_train['host_vec']),\n#                      np.vstack(X_train['question_user_name_vec']),\n#                      np.vstack(X_train['answer_user_name_vec']),\n                     np.array(question_title_vectors_train)[:,0,:],\n                     np.array(question_body_vectors_train)[:,0,:],\n                     np.array(answer_vectors_train)[:,0,:],\n                     np.vstack(X_train['question_title_tfidf_vec']),\n                     np.vstack(X_train['question_body_tfidf_vec']),\n                     np.vstack(X_train['answer_tfidf_vec'])\n                     ], axis = 1)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"                     \nX_test = np.concatenate([\n                     np.vstack(X_test['category_vec']),\n                     np.vstack(X_test['host_vec']),\n#                      np.vstack(X_test['question_user_name_vec']),\n#                      np.vstack(X_test['answer_user_name_vec']),\n                     np.array(question_title_vectors_test)[:,0,:],\n                     np.array(question_body_vectors_test)[:,0,:],\n                     np.array(answer_vectors_test)[:,0,:],\n                     np.vstack(X_test['question_title_tfidf_vec']),\n                     np.vstack(X_test['question_body_tfidf_vec']),\n                     np.vstack(X_test['answer_tfidf_vec'])\n                     ], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.DataFrame(X_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.DataFrame(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y_train","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 4. Modeling and training"},{"metadata":{"trusted":true},"cell_type":"code","source":"class SpearmanCallback(Callback):\n    '''\n    Class for calculating and displaing Spearman Rho value\n    as a callback after each epoch.\n    '''\n    def __init__(self, validation_data, model_name):\n        self.x_val = validation_data[0]\n        self.y_val = validation_data[1]\n        \n        self.model_name = model_name\n\n    def on_epoch_end(self, epoch, logs={}):\n        y_pred_val = self.model.predict(self.x_val)\n        rho_val = np.mean([spearmanr(np.array(self.y_val)[:, 0, ind], np.array(y_pred_val)[:, 0, ind]).correlation for ind in range(y_pred_val.shape[1])])\n        \n        #self.model.save_weights(self.model_name)\n        print('validation rho spearman callback value: {}'.format(rho_val))\n        return rho_val","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_model():\n    inps = Input(shape=(1, X_train.shape[1]))\n    x = LSTM(128, dropout=0.2, return_sequences=True)(inps)\n    x = Dense(128, activation='elu')(x)\n    x = Dropout(0.2)(x)\n    y = Dense(Y_train.shape[1], activation='sigmoid')(x)\n    model = Model(inputs=inps, outputs=y)\n\n    model.compile(\n        optimizer=Adam(), # to check\n        loss=['binary_crossentropy'] #'mean_squared_error'\n    )\n    model.summary()\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_predictions = []\n\nkf = KFold(n_splits=5, random_state=42, shuffle=True)\n\nX_test_tmp = X_test.reshape(-1, 1, X_test.shape[1])\n\nfor ind, (train, validation) in enumerate(kf.split(X_train)):\n    X_train_part= X_train[train]\n    Y_train_part = Y_train.iloc[train, :]\n    X_validate_part = X_train[validation]\n    Y_validate_part = Y_train.iloc[validation, :]\n    \n    X_train_part = X_train_part.reshape(-1, 1, X_train.shape[1])\n    Y_train_part = np.array(Y_train_part).reshape(-1, 1, Y_train.shape[1])\n    X_validate_part = X_validate_part.reshape(-1, 1, X_validate_part.shape[1])\n    Y_validate_part = np.array(Y_validate_part).reshape(-1, 1, Y_validate_part.shape[1])\n    \n    model = create_model()\n    model.fit(X_train_part, Y_train_part, epochs=100, batch_size=32, validation_data=(X_validate_part, Y_validate_part), verbose=True,\n        callbacks=[SpearmanCallback(validation_data=(X_validate_part, Y_validate_part), model_name=f'best_model_batch{ind}.h5')])\n    all_predictions.append(model.predict(X_test_tmp))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Add MultiTaskElasticNet here using X_test_tmp\n# and reshape predictions then append to all_predictions\nkf = KFold(n_splits=5, random_state=42, shuffle=True)\n\npred_mt = []\nfor ind, (train, val) in enumerate(kf.split(X_train)):\n    X_train_part= X_train[train]\n    Y_train_part = Y_train.iloc[train, :]\n\n    model = MultiTaskElasticNet(alpha=0.001)\n    model.fit(X_train_part, Y_train_part)\n    pred_mt.append(model.predict(X_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_pred_stash = all_predictions\nall_pred_stash","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"all_predictions = np.concatenate([np.array(all_predictions)[:,:,0,:], np.array(pred_mt)])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 4.1. Averaging predictions"},{"metadata":{"trusted":true},"cell_type":"code","source":"final = pd.DataFrame(np.array(all_predictions)[0,:,:])\nfinal = pd.concat([pd.DataFrame(np.array(all_predictions)[valid_pred,:,:]) for valid_pred in range(10)], axis=1)\nfor num in range(31):\n    final[num] = final.iloc[:, [num * valid_pred for valid_pred in range(10)]].mean(axis=1)\nfinal = final.iloc[:, :31]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 4.2. Submiting "},{"metadata":{"trusted":true},"cell_type":"code","source":"final.columns = sample_submission.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final['qa_id'] = sample_submission['qa_id']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"}},"nbformat":4,"nbformat_minor":1}